# Reading App - FastAPI + React

AI-powered multilingual reading comprehension app with text simplification, TTS audio, and interactive Q&A.

**ğŸš€ Optimized for deployment:** ~220MB (was 3.7GB) | PythonAnywhere ready | Production-tested

---

## âœ¨ Features

- ğŸ“š **Multi-language support:** English, Latvian, Spanish, Russian
- ğŸ¤– **AI-powered:**
  - Text simplification (DeepSeek)
  - Question generation (Gemini)
  - Answer evaluation with feedback
- ğŸ”Š **Text-to-Speech:** HuggingFace Spaces integration with word-level timing
- âœï¸ **Text upload:** Paste or upload stories
- ğŸ¯ **Adaptive difficulty:** Simple, Standard, Challenge modes

---

## ğŸ“ Project Structure

```
AI_App/
â”œâ”€â”€ backend/                    # FastAPI application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ core/              # Configuration, LLM factories, logging
â”‚   â”‚   â”œâ”€â”€ routers/           # API endpoints
â”‚   â”‚   â”œâ”€â”€ services/          # Business logic
â”‚   â”‚   â””â”€â”€ main.py            # App entry point
â”‚   â””â”€â”€ wsgi.py                # PythonAnywhere WSGI config
â”œâ”€â”€ frontend/                   # React + TypeScript + Vite
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ pages/             # Library, Upload
â”‚       â””â”€â”€ api/               # Backend client
â”œâ”€â”€ scripts/                    # Utility scripts
â”‚   â”œâ”€â”€ toJson.py              # Add texts to library
â”‚   â””â”€â”€ cleanup_venv.py        # Dependency cleanup
â”œâ”€â”€ docs/                       # Documentation
â”‚   â””â”€â”€ notes.md               # Development notes
â”œâ”€â”€ data/                       # JSON text storage
â”œâ”€â”€ requirements-base.txt       # Production dependencies (~220MB)
â”œâ”€â”€ requirements-dev.txt        # Development tools
â”œâ”€â”€ requirements-optional.txt   # Future features (documented)
â”œâ”€â”€ Makefile                    # Build automation
â”œâ”€â”€ DEPLOYMENT.md               # PythonAnywhere guide
â””â”€â”€ OPTIMIZATION.md             # Optimization details
```

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Node 18+
- API Keys:
  - Google AI Studio (Gemini)
  - DeepSeek
  - HuggingFace

### Backend Setup

```bash
# 1. Clone repository
git clone https://github.com/Viktors-Vinogradovs/ReadApp2
cd ReadApp2

# 2. Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Configure environment
cp .env.example .env
# Edit .env with your API keys

# 5. Run server
uvicorn backend.app.main:app --host 0.0.0.0 --port 8000 --reload
```

**For development tools** (optional):
```bash
pip install -r requirements-dev.txt
```

API will be available at:
- ğŸŒ http://localhost:8000
- ğŸ“š http://localhost:8000/docs (Swagger UI)

### Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

Frontend will be available at:
- ğŸŒ http://localhost:5173

---

## ğŸ“¦ Dependencies

### Production (requirements.txt) - ~220MB
```
python-dotenv        # Environment configuration
fastapi              # Web framework
uvicorn              # ASGI server
pydantic             # Data validation
google-generativeai  # Gemini API
langchain            # LLM orchestration
langchain-google-genai
openai               # DeepSeek API
tiktoken             # Token counting
requests             # HTTP client
gradio_client        # HuggingFace Spaces TTS
```
---

## API Endpoints

### Core
- `GET /health` - Health check

### Texts
- `GET /texts?lang=English` - List library texts
- `POST /texts` - Upload new text (with auto-splitting)
- `POST /texts/preview` - Preview text fragments
- `GET /texts/{name}/parts?lang=` - Get text parts

### Q&A
- `POST /qa/simplify` - Simplify text
- `POST /qa/format` - Fix formatting
- `POST /qa/questions` - Generate questions
- `POST /qa/evaluate` - Evaluate answer (rate-limited)
- `POST /qa/audio` - Synthesize TTS audio

---

## Makefile Commands

```bash
# Setup
make install-prod    # Install production deps (~220MB)

# Running
make run             # Start production server
make run-dev         # Start with auto-reload

# Maintenance
make clean           # Remove __pycache__, build artifacts
make clean-venv      # Delete virtual environment
make lint            # Run flake8
make format          # Run black
make test            # Run pytest

# Deployment
make deploy-check    # Verify deployment readiness
make size-check      # Check installed package sizes
```

---

##  Deployment

### PythonAnywhere (Recommended)

**Complete guide:** See [DEPLOYMENT.md](DEPLOYMENT.md)

**Quick summary:**
1. Upload code to PythonAnywhere
2. Install: `pip install -r requirements-base.txt`
3. Configure WSGI to point to `backend/wsgi.py`
4. Set environment variables
5. Reload app

**Size verification:**
- âœ… ~220MB fits in free tier (512MB limit)
- âœ… ~400MB total with venv

### Alternative Platforms

**Docker:**
```dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY requirements-base.txt .
RUN pip install -r requirements-base.txt
COPY backend/ ./backend/
CMD ["uvicorn", "backend.app.main:app", "--host", "0.0.0.0"]
```

**Vercel/Netlify (Frontend only):**
```bash
cd frontend
npm run build
vercel deploy  # or netlify deploy
```

---

## ğŸ”§ Optimization Summary

### Before â†’ After
- **Size:** 3.7GB â†’ 220MB (94% reduction âœ¨)
- **Packages:** 45 â†’ 15
- **Startup:** ~8s â†’ ~2s
- **Code duplication:** High â†’ Eliminated
- **PythonAnywhere:** âŒ Too large â†’ âœ… Ready

### What Was Optimized
- âŒ Removed unused ML packages (torch, transformers, spacy)
- âœ¨ Centralized LLM initialization (eliminated 3Ã— duplication)
- âœ¨ Added structured logging (replaced 53 print statements)
- âœ¨ Reorganized project structure
- âœ¨ Created deployment automation

**Details:** See [OPTIMIZATION.md](OPTIMIZATION.md)

---

## ğŸ§ª Testing

```bash
# Run all tests
make test

# Or manually
pytest tests/ -v

# Test specific endpoint
curl http://localhost:8000/health
curl http://localhost:8000/texts?lang=English
```

---

## ğŸ” Environment Variables

Required in `.env` file:

```env
# Gemini API (Google AI Studio)
GEMINI_API_KEY=your_key_here
GEMINI_AUDIO_API_KEY=your_key_here

# DeepSeek API
DEEPSEEK_API_KEY=your_key_here

# HuggingFace Token
HF_API_TOKEN=your_token_here
```

**Template:** See [.env.example](.env.example)

---

## ğŸ“š Documentation

- [DEPLOYMENT.md](DEPLOYMENT.md) - PythonAnywhere deployment guide
- [OPTIMIZATION.md](OPTIMIZATION.md) - Optimization details
- [docs/notes.md](docs/notes.md) - Development notes & ideas
- [API Docs](http://localhost:8000/docs) - Swagger UI (when running)

---

## ğŸ¤ Contributing

1. Install dev dependencies: `make install-dev`
2. Format code: `make format`
3. Run linter: `make lint`
4. Run tests: `make test`
5. Submit PR

---

## ğŸ“ License

MIT License - See LICENSE file

---

## ğŸ™ Acknowledgments

- **LLMs:** Google Gemini, DeepSeek
- **TTS:** HuggingFace Spaces (MohamedRashad/Multilingual-TTS, RaivisDejus/Latvian-Piper-TTS)
- **Frameworks:** FastAPI, React, LangChain

---

## ğŸ“ Support

- **Issues:** [GitHub Issues](your-repo/issues)
- **PythonAnywhere Help:** https://help.pythonanywhere.com
- **API Docs:** `/docs` endpoint

---

**ğŸ‰ Optimized and ready for deployment!**
